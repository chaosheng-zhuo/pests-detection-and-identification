{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d5dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de68efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module 0: Data Loading Utilities\n",
    "def load_yaml(yaml_path):\n",
    "    \"\"\"Load dataset configuration from YAML.\"\"\"\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    return data\n",
    "\n",
    "def get_paths(root_dir, split):\n",
    "    img_dir = os.path.join(root_dir, split, 'images')\n",
    "    label_dir = os.path.join(root_dir, split, 'labels')\n",
    "    \n",
    "    if not os.path.exists(img_dir):\n",
    "        print(f\"错误：{img_dir} 不存在\")\n",
    "        return [], []\n",
    "    \n",
    "    img_files = [f for f in os.listdir(img_dir) \n",
    "                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    imgs = [os.path.join(img_dir, f) for f in img_files]\n",
    "    \n",
    "    matched = 0\n",
    "    labels = []\n",
    "    for img_file in img_files:\n",
    "        stem = os.path.splitext(img_file)[0]  # 去掉 .jpg\n",
    "        label_file = stem + '.txt'\n",
    "        label_path = os.path.join(label_dir, os.path.basename(label_file))\n",
    "        if os.path.exists(label_path):\n",
    "            labels.append(label_path)\n",
    "            matched += 1\n",
    "    \n",
    "    match_rate = matched / len(imgs) if imgs else 0\n",
    "    unique_stem_rate = len(set(os.path.splitext(f)[0] for f in img_files)) / len(img_files)\n",
    "    \n",
    "    print(f\"{split:>5}: {len(imgs):>5} 图像, {len(labels):>5} 标签, \"\n",
    "          f\"标签匹配: {match_rate:.1%}, 图像唯一性: {unique_stem_rate:.1%}\")\n",
    "    \n",
    "    return imgs, labels\n",
    "\n",
    "# Module 1: Data Quantity Statistics\n",
    "def analyze_data_quantity(root_dir, splits=['train', 'val', 'test']):\n",
    "    \"\"\"Analyze image and label counts per split.\"\"\"\n",
    "    stats = {}\n",
    "    for split in splits:\n",
    "        imgs, labels = get_paths(root_dir, split)\n",
    "        stats[split] = {\n",
    "            'images': len(imgs),\n",
    "            'labels': len(labels),\n",
    "            'match': len(imgs) == len(labels)\n",
    "        }\n",
    "    return stats\n",
    "\n",
    "# Module 2: Class Distribution\n",
    "def analyze_class_distribution(label_paths, class_names):\n",
    "    \"\"\"Count occurrences per class.\"\"\"\n",
    "    class_counts = Counter()\n",
    "    for label_path in label_paths:\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            cls = int(line.split()[0])\n",
    "            class_counts[cls] += 1\n",
    "    df = pd.DataFrame({'class': class_names, 'count': [class_counts[i] for i in range(len(class_names))]})\n",
    "    max_min_ratio = df['count'].max() / df['count'].min() if df['count'].min() > 0 else float('inf')\n",
    "    return df, max_min_ratio\n",
    "\n",
    "def visualize_class_distribution(df, output_path):\n",
    "    \"\"\"Plot class distribution bar chart.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='class', y='count', data=df)\n",
    "    plt.title('Class Distribution')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "# Module 3: Image Sizes and Aspect Ratios\n",
    "def analyze_image_sizes(img_paths):\n",
    "    \"\"\"Collect width, height, and aspect ratios.\"\"\"\n",
    "    sizes = []\n",
    "    for img_path in tqdm(img_paths, desc=\"Analyzing sizes\"):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue  # Skip invalid images\n",
    "        h, w = img.shape[:2]\n",
    "        sizes.append((w, h, w / h))\n",
    "    df = pd.DataFrame(sizes, columns=['width', 'height', 'aspect_ratio'])\n",
    "    return df\n",
    "\n",
    "def visualize_image_sizes(df, output_path):\n",
    "    \"\"\"Plot histograms for sizes and aspect ratios.\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df['width'], kde=True, color='blue', label='Width')\n",
    "    sns.histplot(df['height'], kde=True, color='red', label='Height')\n",
    "    plt.title('Width and Height Distribution')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(df['aspect_ratio'], kde=True)\n",
    "    plt.title('Aspect Ratio Distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "# Module 4: Bounding Box Quality\n",
    "def analyze_bbox_quality(label_paths):\n",
    "    \"\"\"Check for invalid or empty bounding boxes.\"\"\"\n",
    "    invalid = 0\n",
    "    empty = 0\n",
    "    total_bboxes = 0\n",
    "    for label_path in label_paths:\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        if not lines:\n",
    "            empty += 1\n",
    "            continue\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) != 5:\n",
    "                invalid += 1\n",
    "                continue\n",
    "            cls, x, y, w, h = map(float, parts)\n",
    "            if any(v <= 0 for v in [w, h]) or x < 0 or y < 0 or x > 1 or y > 1:\n",
    "                invalid += 1\n",
    "            total_bboxes += 1\n",
    "    return invalid, empty, total_bboxes\n",
    "\n",
    "def visualize_random_samples(img_paths, label_paths, class_names, num_samples=5, output_path=None):\n",
    "    \"\"\"Visualize random images with bounding boxes.\"\"\"\n",
    "    samples = random.sample(range(len(img_paths)), min(num_samples, len(img_paths)))\n",
    "    fig, axs = plt.subplots(1, len(samples), figsize=(20, 5))\n",
    "    for i, idx in enumerate(samples):\n",
    "        img = cv2.imread(img_paths[idx])\n",
    "        h, w = img.shape[:2]\n",
    "        with open(label_paths[idx], 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) != 5: continue\n",
    "            cls, x, y, bw, bh = map(float, parts)\n",
    "            x1 = int((x - bw/2) * w)\n",
    "            y1 = int((y - bh/2) * h)\n",
    "            x2 = int((x + bw/2) * w)\n",
    "            y2 = int((y + bh/2) * h)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(img, class_names[int(cls)], (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        axs[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axs[i].axis('off')\n",
    "    if output_path:\n",
    "        plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "# Module 5: Objects per Image\n",
    "def analyze_objects_per_image(label_paths):\n",
    "    \"\"\"Calculate objects count per image.\"\"\"\n",
    "    counts = []\n",
    "    for label_path in label_paths:\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        counts.append(len(lines))\n",
    "    df = pd.DataFrame({'objects': counts})\n",
    "    return df['objects'].mean(), df['objects'].max(), df\n",
    "\n",
    "def visualize_objects_per_image(df, output_path):\n",
    "    \"\"\"Plot histogram of objects per image.\"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df['objects'], kde=True)\n",
    "    plt.title('Objects per Image Distribution')\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "# Module 6: Image Quality (Brightness & Blur)\n",
    "def analyze_image_quality(img_paths):\n",
    "    \"\"\"Compute brightness and blur metrics.\"\"\"\n",
    "    brightness = []\n",
    "    blur = []\n",
    "    for img_path in tqdm(img_paths, desc=\"Analyzing quality\"):\n",
    "        img = cv2.imread(img_path, 0)\n",
    "        if img is None:\n",
    "            continue\n",
    "        brightness.append(np.mean(img))\n",
    "        lap = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "        blur.append(lap)\n",
    "    df = pd.DataFrame({'brightness': brightness, 'blur': blur})\n",
    "    return df\n",
    "\n",
    "def visualize_image_quality(df, output_path):\n",
    "    \"\"\"Plot distributions for brightness and blur.\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(df['brightness'], kde=True)\n",
    "    plt.title('Brightness Distribution')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(df['blur'], kde=True)\n",
    "    plt.title('Blur (Laplacian Variance) Distribution')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def get_extreme_samples(img_paths, df, num=3):\n",
    "    \"\"\"Get paths of extreme images (dark, bright, blurry).\"\"\"\n",
    "    dark = df.nsmallest(num, 'brightness').index\n",
    "    bright = df.nlargest(num, 'brightness').index\n",
    "    blurry = df.nsmallest(num, 'blur').index\n",
    "    extremes = [img_paths[i] for i in list(dark) + list(bright) + list(blurry)]\n",
    "    return extremes\n",
    "\n",
    "# Module 7: Class Visual Differences\n",
    "def collect_class_samples(img_paths, label_paths, class_names, num_per_class=3):\n",
    "    \"\"\"Collect sample images per class.\"\"\"\n",
    "    class_imgs = {i: [] for i in range(len(class_names))}\n",
    "    for img_path, label_path in zip(img_paths, label_paths):\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        classes = set([int(line.split()[0]) for line in lines if line.strip()])\n",
    "        for cls in classes:\n",
    "            if len(class_imgs[cls]) < num_per_class:\n",
    "                class_imgs[cls].append(img_path)\n",
    "    return class_imgs\n",
    "\n",
    "def visualize_class_samples(class_imgs, class_names, output_path):\n",
    "    \"\"\"Plot grid of sample images per class.\"\"\"\n",
    "    num_classes = len(class_imgs)\n",
    "    rows, cols = (3, 4) if num_classes >= 12 else (1, num_classes)\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(12, 9) if num_classes >= 12 else (20, 5))\n",
    "    axs = axs.flatten()\n",
    "    for i, (cls, imgs) in enumerate(class_imgs.items()):\n",
    "        if imgs:\n",
    "            img = cv2.imread(imgs[0])\n",
    "            axs[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            axs[i].set_title(class_names[cls])\n",
    "            axs[i].axis('off')\n",
    "    for j in range(i + 1, len(axs)):\n",
    "        axs[j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "def extract_histogram_features(img_paths):\n",
    "    \"\"\"Extract color histogram features.\"\"\"\n",
    "    features = []\n",
    "    for img_path in img_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        hist = cv2.calcHist([img], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256]).flatten()\n",
    "        features.append(hist)\n",
    "    return np.array(features)\n",
    "\n",
    "def analyze_and_visualize_clustering(features, labels, output_path):\n",
    "    \"\"\"Perform PCA/t-SNE and plot.\"\"\"\n",
    "    if len(features) == 0:\n",
    "        return\n",
    "    pca = PCA(n_components=2).fit_transform(features)\n",
    "    tsne = TSNE(n_components=2).fit_transform(features)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.scatterplot(x=pca[:,0], y=pca[:,1], hue=labels, palette='viridis')\n",
    "    plt.title('PCA Clustering')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.scatterplot(x=tsne[:,0], y=tsne[:,1], hue=labels, palette='viridis')\n",
    "    plt.title('t-SNE Clustering')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "# Module 8: Split Consistency\n",
    "def analyze_split_consistency(root_dir, class_names, splits=['train', 'val', 'test']):\n",
    "    \"\"\"Compare distributions across splits.\"\"\"\n",
    "    class_dfs = {}\n",
    "    size_dfs = {}\n",
    "    obj_dfs = {}\n",
    "    for split in splits:\n",
    "        imgs, labels = get_paths(root_dir, split)\n",
    "        class_dfs[split] = analyze_class_distribution(labels, class_names)[0]\n",
    "        size_dfs[split] = analyze_image_sizes(imgs)\n",
    "        _, _, obj_dfs[split] = analyze_objects_per_image(labels)\n",
    "    return class_dfs, size_dfs, obj_dfs\n",
    "\n",
    "def visualize_split_consistency(class_dfs, size_dfs, obj_dfs, output_paths):\n",
    "    \"\"\"Plot comparisons for classes, sizes, objects.\"\"\"\n",
    "    # Class distribution\n",
    "    combined_class = pd.concat([df.assign(split=split) for split, df in class_dfs.items()])\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='class', y='count', hue='split', data=combined_class)\n",
    "    plt.title('Class Distribution Across Splits')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(output_paths[0])\n",
    "    plt.close()\n",
    "    \n",
    "    # Aspect ratios\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for split, df in size_dfs.items():\n",
    "        sns.kdeplot(df['aspect_ratio'], label=split)\n",
    "    plt.title('Aspect Ratio Distribution Across Splits')\n",
    "    plt.legend()\n",
    "    plt.savefig(output_paths[1])\n",
    "    plt.close()\n",
    "    \n",
    "    # Objects per image\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for split, df in obj_dfs.items():\n",
    "        sns.kdeplot(df['objects'], label=split)\n",
    "    plt.title('Objects per Image Across Splits')\n",
    "    plt.legend()\n",
    "    plt.savefig(output_paths[2])\n",
    "    plt.close()\n",
    "\n",
    "# Module 9: Data Augmentation Suggestions\n",
    "def generate_augmentation_suggestions(class_df, max_min_ratio, size_df, bbox_invalid, bbox_total, avg_obj, quality_df):\n",
    "    \"\"\"Generate suggestions based on analyses.\"\"\"\n",
    "    suggestions = []\n",
    "    if max_min_ratio > 3:\n",
    "        suggestions.append(('样本极度不平衡', '类别平衡采样，增加稀有类数据增强'))\n",
    "    if size_df['width'].std() > 100 or size_df['height'].std() > 100:\n",
    "        suggestions.append(('尺寸差异大', 'Resize+Pad 保持长宽比'))\n",
    "    if quality_df['blur'].mean() < 50:  # Adjustable threshold\n",
    "        suggestions.append(('模糊样本较多', '使用 A.Sharpen 、A.MotionBlur 增强'))\n",
    "    if quality_df['brightness'].min() < 50 or quality_df['brightness'].max() > 200:\n",
    "        suggestions.append(('夜间样本少', '光照增强（CLAHE等）'))\n",
    "    if avg_obj > 5:\n",
    "        suggestions.append(('背景复杂遮挡多', 'Mosaic / MixUp 增强有效'))\n",
    "    return pd.DataFrame(suggestions, columns=['问题', '策略'])\n",
    "\n",
    "# Report Generation\n",
    "def generate_report(output_dir, qty_stats, class_df, max_min_ratio, invalid, empty, total_bboxes, avg_obj, max_obj, suggestions):\n",
    "    \"\"\"Generate Markdown report with results and images.\"\"\"\n",
    "    report = \"\"\"\n",
    "# AgroPest-12 EDA Report\n",
    "\n",
    "## 1. Data Quantity\n",
    "{0}\n",
    "\n",
    "## 2. Class Distribution\n",
    "Max/Min Ratio: {1:.2f}\n",
    "![Class Dist](class_dist.png)\n",
    "\n",
    "## 3. Image Sizes\n",
    "![Sizes](sizes.png)\n",
    "\n",
    "## 4. BBox Quality\n",
    "Invalid: {2}/{3} ({4:.2f}%)\n",
    "Empty: {5}\n",
    "![Samples](samples.png)\n",
    "\n",
    "## 5. Objects per Image\n",
    "Avg: {6:.2f}, Max: {7}\n",
    "![Objects Hist](objects_hist.png)\n",
    "\n",
    "## 6. Image Quality\n",
    "![Quality](quality.png)\n",
    "Extreme Samples: extreme_0.jpg, extreme_1.jpg, ... (check folder)\n",
    "\n",
    "## 7. Class Differences\n",
    "![Class Samples](class_samples.png)\n",
    "![Clustering](clustering.png)\n",
    "\n",
    "## 8. Split Consistency\n",
    "![Class Consist](class_consist.png)\n",
    "![Size Consist](size_consist.png)\n",
    "![Obj Consist](obj_consist.png)\n",
    "\n",
    "## 9. Augmentation Suggestions\n",
    "{8}\n",
    "\"\"\".format(\n",
    "        qty_stats,\n",
    "        max_min_ratio,\n",
    "        invalid, total_bboxes, (invalid / total_bboxes * 100) if total_bboxes > 0 else 0,\n",
    "        empty,\n",
    "        avg_obj, max_obj,\n",
    "        suggestions.to_markdown(index=False)\n",
    "    )\n",
    "    report_path = os.path.join(output_dir, 'report.md')\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(report)\n",
    "    print(f\"Report generated at: {report_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f21778a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检测到 12 个类别: ['Ants', 'Bees', 'Beetles', 'Caterpillars', 'Earthworms', 'Earwigs', 'Grasshoppers', 'Moths', 'Slugs', 'Snails', 'Wasps', 'Weevils']\n",
      "\n",
      "=== 数据集结构检查 ===\n",
      "train: 11502 图像, 11502 标签, 标签匹配: 100.0%, 图像唯一性: 100.0%\n",
      "valid:  1095 图像,  1095 标签, 标签匹配: 100.0%, 图像唯一性: 100.0%\n",
      " test:   546 图像,   546 标签, 标签匹配: 100.0%, 图像唯一性: 100.0%\n"
     ]
    }
   ],
   "source": [
    "root_dir='data/AgroPest12'\n",
    "output_dir='eda_outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "# 加载配置\n",
    "yaml_path = os.path.join(root_dir, 'data.yaml')\n",
    "if not os.path.exists(yaml_path):\n",
    "    raise FileNotFoundError(f\"找不到 data.yaml，请确保在 {root_dir} 目录下\")\n",
    "\n",
    "config = load_yaml(yaml_path)\n",
    "class_names = config.get('names', [])\n",
    "print(f\"检测到 {len(class_names)} 个类别: {class_names}\")\n",
    "\n",
    "# 加载所有数据路径（适配新结构）\n",
    "splits = ['train', 'valid', 'test']\n",
    "all_imgs = {}\n",
    "all_labels = {}\n",
    "\n",
    "print(\"\\n=== 数据集结构检查 ===\")\n",
    "for split in splits:\n",
    "    imgs, labels = get_paths(root_dir, split)\n",
    "    all_imgs[split] = imgs\n",
    "    all_labels[split] = labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f12cea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. 数据量统计:\n",
      "      images labels match_rate\n",
      "train  11502  11502       True\n",
      "valid   1095   1095       True\n",
      "test     546    546       True\n"
     ]
    }
   ],
   "source": [
    "# 1. 数据量统计\n",
    "qty_stats = {\n",
    "    split: {'images': len(imgs), 'labels': len(labels), 'match_rate': len(imgs) == len(labels)}\n",
    "    for split, (imgs, labels) in zip(splits, [(all_imgs[s], all_labels[s]) for s in splits])\n",
    "}\n",
    "print(\"\\n1. 数据量统计:\")\n",
    "print(pd.DataFrame(qty_stats).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54fba4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. 类别分布分析...\n",
      "最大/最小类别比例: 2.43\n",
      "           class  count\n",
      "0           Ants   2231\n",
      "3   Caterpillars   1740\n",
      "1           Bees   1596\n",
      "9         Snails   1199\n",
      "5        Earwigs   1182\n",
      "10         Wasps   1167\n",
      "4     Earthworms   1083\n",
      "6   Grasshoppers   1071\n",
      "7          Moths   1062\n",
      "2        Beetles   1058\n",
      "11       Weevils    975\n",
      "8          Slugs    918\n"
     ]
    }
   ],
   "source": [
    "# 2. 类别分布（基于train）\n",
    "print(\"\\n2. 类别分布分析...\")\n",
    "class_df, max_min_ratio = analyze_class_distribution(all_labels['train'], class_names)\n",
    "print(f\"最大/最小类别比例: {max_min_ratio:.2f}\")\n",
    "print(class_df.sort_values('count', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9a2df17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. 图像尺寸分析...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing sizes: 100%|██████████| 11502/11502 [00:23<00:00, 489.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尺寸范围: 640x640 ~ 640x640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. 图像尺寸\n",
    "print(\"\\n3. 图像尺寸分析...\")\n",
    "size_df_train = analyze_image_sizes(all_imgs['train'])\n",
    "print(f\"尺寸范围: {size_df_train['width'].min()}x{size_df_train['height'].min()} ~ {size_df_train['width'].max()}x{size_df_train['height'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd0d92f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. 标注质量检查...\n",
      "无效框: 0/17312 (0.00%)\n",
      "空标签文件: 3/13143 (0.02%)\n"
     ]
    }
   ],
   "source": [
    "# 4. 标注质量检查（全部数据）\n",
    "print(\"\\n4. 标注质量检查...\")\n",
    "all_label_paths = []\n",
    "for labels in all_labels.values():\n",
    "    all_label_paths.extend(labels)\n",
    "invalid, empty, total_bboxes = analyze_bbox_quality(all_label_paths)\n",
    "print(f\"无效框: {invalid}/{total_bboxes} ({invalid/total_bboxes*100:.2f}%)\")\n",
    "print(f\"空标签文件: {empty}/{len(all_label_paths)} ({empty/len(all_label_paths)*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d57dc30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. 每图平均目标数: 1.33, 最大: 49\n"
     ]
    }
   ],
   "source": [
    "# 5. 每图目标数\n",
    "avg_obj, max_obj, _ = analyze_objects_per_image(all_labels['train'])\n",
    "print(f\"5. 每图平均目标数: {avg_obj:.2f}, 最大: {max_obj}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "717553bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. 图像质量分析...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing quality: 100%|██████████| 11502/11502 [00:51<00:00, 224.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均亮度: 118.5, 平均清晰度: 159.7\n",
      "\n",
      "7. 生成可视化图表...\n",
      "\n",
      "✅ EDA 完成！结果保存在: eda_outputs\n",
      "\n",
      "9. 数据增强建议:\n",
      "      问题            策略\n",
      "0  夜间样本少  光照增强（CLAHE等）\n",
      "Report generated at: eda_outputs\\report.md\n",
      "{'qty_stats': {'train': {'images': 11502, 'labels': 11502, 'match_rate': True}, 'valid': {'images': 1095, 'labels': 1095, 'match_rate': True}, 'test': {'images': 546, 'labels': 546, 'match_rate': True}}, 'class_df':            class  count\n",
      "0           Ants   2231\n",
      "1           Bees   1596\n",
      "2        Beetles   1058\n",
      "3   Caterpillars   1740\n",
      "4     Earthworms   1083\n",
      "5        Earwigs   1182\n",
      "6   Grasshoppers   1071\n",
      "7          Moths   1062\n",
      "8          Slugs    918\n",
      "9         Snails   1199\n",
      "10         Wasps   1167\n",
      "11       Weevils    975, 'max_min_ratio': np.float64(2.4302832244008714), 'bbox_quality': (0, 3, 17312), 'objects_stats': (np.float64(1.3286384976525822), np.int64(49)), 'suggestions':       问题            策略\n",
      "0  夜间样本少  光照增强（CLAHE等）}\n"
     ]
    }
   ],
   "source": [
    "# 6. 图像质量\n",
    "print(\"\\n6. 图像质量分析...\")\n",
    "quality_df = analyze_image_quality(all_imgs['train'])\n",
    "print(f\"平均亮度: {quality_df['brightness'].mean():.1f}, 平均清晰度: {quality_df['blur'].mean():.1f}\")\n",
    "\n",
    "# 生成所有可视化\n",
    "print(\"\\n7. 生成可视化图表...\")\n",
    "\n",
    "# 类别分布图\n",
    "visualize_class_distribution(class_df, os.path.join(output_dir, 'class_dist.png'))\n",
    "\n",
    "# 尺寸分布图\n",
    "visualize_image_sizes(size_df_train, os.path.join(output_dir, 'sizes.png'))\n",
    "\n",
    "# 随机样本可视化\n",
    "visualize_random_samples(all_imgs['train'], all_labels['train'], class_names, \n",
    "                        num_samples=8, output_path=os.path.join(output_dir, 'samples.png'))\n",
    "\n",
    "# 每图目标数分布\n",
    "_, _, obj_df = analyze_objects_per_image(all_labels['train'])\n",
    "visualize_objects_per_image(obj_df, os.path.join(output_dir, 'objects_hist.png'))\n",
    "\n",
    "# 质量分布\n",
    "visualize_image_quality(quality_df, os.path.join(output_dir, 'quality.png'))\n",
    "\n",
    "# 类别样本展示\n",
    "class_imgs = collect_class_samples(all_imgs['train'], all_labels['train'], class_names)\n",
    "visualize_class_samples(class_imgs, class_names, os.path.join(output_dir, 'class_samples.png'))\n",
    "\n",
    "# 数据增强建议\n",
    "suggestions = generate_augmentation_suggestions(\n",
    "    class_df, max_min_ratio, size_df_train, invalid, total_bboxes, avg_obj, quality_df\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ EDA 完成！结果保存在: {output_dir}\")\n",
    "print(\"\\n9. 数据增强建议:\")\n",
    "print(suggestions)\n",
    "\n",
    "# 生成报告\n",
    "generate_report(output_dir, qty_stats, class_df, max_min_ratio, invalid, empty, \n",
    "                total_bboxes, avg_obj, max_obj, suggestions)\n",
    "\n",
    "print({\n",
    "    'qty_stats': qty_stats,\n",
    "    'class_df': class_df,\n",
    "    'max_min_ratio': max_min_ratio,\n",
    "    'bbox_quality': (invalid, empty, total_bboxes),\n",
    "    'objects_stats': (avg_obj, max_obj),\n",
    "    'suggestions': suggestions\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
